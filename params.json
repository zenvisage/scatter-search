{
  "name": "Scatter-search",
  "tagline": "An interactive exploration tool for large datasets",
  "body": "# Zenvisage Scatter Search\r\n\r\nScatter Search is a tool to explore large datasets by interacting with its scatter plot. The exploration reveals key insights about the dataset.\r\n\r\nThis application should be viewed as an implementation of ongoing research under the project Zenvisage at the University of Illinois at Urbana Champaign led by [Prof. Aditya Parameswaran][prof].\r\n\r\nThe in-progress research paper can be found [here][researchpaper]. (*Note: Update link*)\r\n\r\n**In a nutshell, one should be able to**:\r\n  - Select the columns one wants to explore (the XAxis, the YAxis and the ZAxis)\r\n  - Draw the region(s) one wants to explore on the representative plot\r\n  - Select the Ranking Algorithm\r\n  - Get a ranked set of scatter plots\r\n\r\n**Notes**:\r\n  - The ZAxis represents the category, or the class, based on which the candidates are ranked.\r\n  - The region(s) are 'drawn' on the representative plot in the form of polygons.\r\n  - The ranking aims to find the order of prominence of candidates in the regions specified.\r\n\r\n### Version\r\n1.0.0\r\n\r\n### Tech\r\n\r\nScatter Search uses a number of open source projects and modules to work properly:\r\n\r\n* [D3] - combines powerful visualization components and a data-driven approach to DOM manipulation\r\n* [Materialize] - A modern responsive front-end framework based on Material Design\r\n* [Python 3.x][python] - evented I/O for the backend\r\n* [Flask] - microframework for Python based on Werkzeug, Jinja 2 and good intentions\r\n* [Numpy] - for computation \r\n* [Pickle] - a python module for object serialization\r\n* [matplotlib] - for its Path.contains_points goodness\r\n* [hopscotch] - An amazing framework to add product tours to their pages.\r\n* [jQuery] - duh\r\n\r\nAnd of course Scatter Search itself is open source with a [public repository][scattersearch]\r\n on GitHub.\r\n\r\n### Getting started - Installation\r\n\r\n#### OS X\r\nScatter Search requires [Python] 3.x to run.\r\n```sh\r\n$ brew install python3\r\n```\r\nDownload the repository and then run pip to install all the dependencies.\r\n```sh\r\n$ git clone https://github.com/zenvisage/scatter-search\r\n$ cd scatter-search\r\n$ pip install --upgrade pip\r\n$ pip install --upgrade -r requirements.txt\r\n```\r\n\r\nThen Run the Flask instance.\r\n```sh\r\n$ python scatter-search.py\r\n```\r\n\r\n#### Windows\r\nRefer to https://www.python.org/downloads/windows/ for downloading and installing the latest version of Python 3.x\r\n\r\nAlso make sure you have git installed and added to the PATH.\r\n\r\nThen run the following commands on the command line:\r\n```sh\r\n$ git clone https://github.com/zenvisage/scatter-search\r\n$ cd scatter-search\r\n$ python -m pip install --upgrade pip\r\n$ python -m pip install --upgrade -r requirements.txt\r\n$ python scatter-search.py\r\n```\r\n\r\n### Adding more datasets\r\nTo add a new dataset file, just add the file to the data/ folder.\r\nAs of now, only .csv and .txt are supported, but incase we'd like to include other formats, it's an easy update.\r\n\r\n**Note:** The included datasets - iris, test, and diabetic_data represent three scenarios. Test wouldn't work because it has just one trivial row. Diabetic_data would be extremely slow and is not fit for the tool. Iris is the small (150 rows only) and easy dataset that I used during development.\r\n\r\n### Extending: Adding indexing methods\r\n\r\nThe app uses Pickle to load and save datasets (in the form of python dictionaries). It's possible to compute and add more information to the dataset *before* saving the dictionary, to help improve performance the next time the dataset is used.\r\nAlso depickling instead of reading the .csv helps load datasets much faster.\r\n```python\r\ndef index_data(data_dict):\r\n    \"\"\"\r\n    This function might be used to index the data dictionary to be more useful\r\n    in sophisticated algorithms.\r\n    Note: In case the file is loaded as pickle, you shouldn't be calling this function.\r\n    :param data_dict: dict, required\r\n    :return: Indexed dictionary\r\n    \"\"\"\r\n    return data_dict\r\n```\r\n*Note: More information about this section soon*\r\n\r\n### Extending: Adding algorithms\r\n\r\n*Note: This section is still in progress.*\r\n\r\nAdding better, more sophisticated algorithms to the application is easy.\r\n\r\n####Define your algorithm function in **utility/algorithms.py**.\r\n\r\nHere is an example of how the existing naive algorithm is implemented. You should be able to see the output as a console log when you click 'Get Results'.\r\n\r\n```python\r\ndef naive_algorithm(polygons, candidates_info, dataset):\r\n    \"\"\"\r\n\r\n    :param polygons: {points: [[x1,y1],[x2,y2],...], type:'green'}\r\n    :param candidates_info: {'CandidateA':numOfOccurrencesInDataset, 'CandidateB'...}\r\n    :param dataset: As described in loadSaveDataset.py\r\n    :return: Must return full dictionaries (same format as dataset) for the top k candidates\r\n    \"\"\"\r\n    return {'comment': 'Hello from the Naive Algorithm'}\r\n\r\n\r\ndef complex_algorithm(polygons, candidates_info, dataset):\r\n    \"\"\"\r\n\r\n    :param polygons:\r\n    :param candidates_info:\r\n    :param dataset:\r\n    :return:\r\n    \"\"\"\r\n    return {'comment': 'Hello from the Complex Algorithm'}\r\n```\r\nAny algorithm takes three parameters:\r\n- polygons\r\n- candidates_info\r\n- dataset\r\n\r\n**polygons** are formatted to easily fit into the matplotlib.PATH object (they form a closed loop).\r\n```python\r\n:param polygons: {points: [[x1,y1],[x2,y2],...], type:'green'}\r\n```\r\n\r\n**candidates_info** is pretty much a map between the candidates and the number of points they have in the dataset.\r\n```python\r\n:param candidates_info: {'CandidateA':numOfOccurrencesInDataset, 'CandidateB'...}\r\n```\r\n\r\nThe format of the **dataset** (as converted from .csv in the loadSaveDataset script) looks like this:\r\n```python\r\ndef get_data_dict(dataset_name, skip_header=0):\r\n    \"\"\"\r\n    Function to get a python dictionary representation of a dataset.\r\n    Only CSVs are supported as of now.\r\n    TODO: Add pickling/depickling.\r\n    :param file_path:   str, required\r\n                        Eg: 'data/iris.csv'\r\n    :param skip_header: int, optional\r\n                        Defaults to 0, otherwise skips the given number of rows\r\n                        Using the last skipped row as column names\r\n    :return:    A python dictionary\r\n                {\r\n                    dataset_name: str,\r\n                    column_names:[str],\r\n                    data: [[row1_val1, row1_val2,...],...],\r\n                    cols: int,\r\n                    rows: int,\r\n                    loaded_from_pickle: bool\r\n                }\r\n                or if an exception was thrown:\r\n                {\r\n                    error: str\r\n                }\r\n    \"\"\"\r\n```\r\n\r\n####Add your algorithm name and function to the mapping dictionary.\r\n```python\r\nEXISTING_ALGORITHMS = {\r\n    'Naive Algorithm': naive_algorithm,\r\n    'Complex Algorithm': complex_algorithm\r\n}\r\n```\r\n\r\nThat's it! Now you should access to the algorithm on the web application.\r\n\r\n### Todos\r\n\r\n - Implement naive algorithm\r\n - Add Results section (also provide a way to control number of top ranks)\r\n - Use Pickle to optimize load time\r\n - Use hopscotch to provide page tour\r\n - Update pending sections.\r\n - Add Usage section.\r\n - Add support for using multiple algorithms at once.\r\n\r\nLicense\r\n----\r\n\r\nMIT\r\n\r\n[//]: # (These are reference links used in the body of this note and get stripped out when the markdown processor does its job. There is no need to format nicely because it shouldn't be seen. Thanks SO - http://stackoverflow.com/questions/4823468/store-comments-in-markdown-syntax)\r\n\r\n   [prof]: http://web.engr.illinois.edu/~adityagp/#\r\n   [d3]: https://d3js.org/\r\n   [materialize]: http://materializecss.com/\r\n   [python]: https://www.python.org/\r\n   [flask]: http://flask.pocoo.org/\r\n   [numpy]: http://www.numpy.org/\r\n   [pickle]:https://docs.python.org/3/library/pickle.html\r\n   [jQuery]: <http://jquery.com>\r\n   [hopscotch]: https://github.com/linkedin/hopscotch\r\n   [scattersearch]: https://github.com/zenvisage/scatter-search\r\n   [researchpaper]:http://web.engr.illinois.edu/~tsiddiq2/doc/zenvisage.pdf\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}